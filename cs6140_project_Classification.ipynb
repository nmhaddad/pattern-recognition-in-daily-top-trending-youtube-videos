{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cs6140_project_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nmhaddad/python-machine-learning-youtube/blob/master/cs6140_project_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTkkR7civapF",
        "colab_type": "text"
      },
      "source": [
        "# **Pattern Recognition in Daily Top Trending YouTube Videos**\n",
        "\n",
        "***\n",
        "\n",
        "NLP Classification Sub-Experiment\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y60Bbpnmt79y",
        "colab_type": "text"
      },
      "source": [
        "# Setup\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyfgaDP9KRS6",
        "colab_type": "text"
      },
      "source": [
        "**Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJwVvfc_yKtR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from google.colab import drive\n",
        "from inspect import signature\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn import metrics\n",
        "from sklearn.pipeline import FeatureUnion\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SM5f7pz99U4K",
        "colab_type": "text"
      },
      "source": [
        "**Load Data From Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bma2ZWaPkKen",
        "colab_type": "code",
        "outputId": "c800c565-520e-47bc-b955-bccad366084e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Qf7kT6_9ejN",
        "colab_type": "text"
      },
      "source": [
        "**Read-in CSV & JSON**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36cOy5BrkVhQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "videos = pd.read_csv(\"/content/drive/My Drive/cs6140 project/data/USvideos.csv\")\n",
        "videos_categories = pd.read_json(\"/content/drive/My Drive/cs6140 project/data/US_category_id.json\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ejKhact3_LM8"
      },
      "source": [
        "# Data Pre-Processing\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UgB67Ybi_JqP"
      },
      "source": [
        "This block of code links the csv to json categories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DC8UI5RhjQoc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# source: https://www.kaggle.com/skalskip/youtube-data-exploration-and-plotly-visualization\n",
        "categories = {category['id']: category['snippet']['title'] for category in videos_categories['items']}\n",
        "videos.insert(4, 'category', videos['category_id'].astype(str).map(categories))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKSLE5f5tl2g",
        "colab_type": "code",
        "outputId": "8d3dec7c-d94c-4261-d51d-4f765df5c986",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        }
      },
      "source": [
        "videos.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_id</th>\n",
              "      <th>trending_date</th>\n",
              "      <th>title</th>\n",
              "      <th>channel_title</th>\n",
              "      <th>category</th>\n",
              "      <th>category_id</th>\n",
              "      <th>publish_time</th>\n",
              "      <th>tags</th>\n",
              "      <th>views</th>\n",
              "      <th>likes</th>\n",
              "      <th>dislikes</th>\n",
              "      <th>comment_count</th>\n",
              "      <th>thumbnail_link</th>\n",
              "      <th>comments_disabled</th>\n",
              "      <th>ratings_disabled</th>\n",
              "      <th>video_error_or_removed</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2kyS6SvSYSE</td>\n",
              "      <td>17.14.11</td>\n",
              "      <td>WE WANT TO TALK ABOUT OUR MARRIAGE</td>\n",
              "      <td>CaseyNeistat</td>\n",
              "      <td>People &amp; Blogs</td>\n",
              "      <td>22</td>\n",
              "      <td>2017-11-13T17:13:01.000Z</td>\n",
              "      <td>SHANtell martin</td>\n",
              "      <td>748374</td>\n",
              "      <td>57527</td>\n",
              "      <td>2966</td>\n",
              "      <td>15954</td>\n",
              "      <td>https://i.ytimg.com/vi/2kyS6SvSYSE/default.jpg</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>SHANTELL'S CHANNEL - https://www.youtube.com/s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1ZAPwfrtAFY</td>\n",
              "      <td>17.14.11</td>\n",
              "      <td>The Trump Presidency: Last Week Tonight with J...</td>\n",
              "      <td>LastWeekTonight</td>\n",
              "      <td>Entertainment</td>\n",
              "      <td>24</td>\n",
              "      <td>2017-11-13T07:30:00.000Z</td>\n",
              "      <td>last week tonight trump presidency|\"last week ...</td>\n",
              "      <td>2418783</td>\n",
              "      <td>97185</td>\n",
              "      <td>6146</td>\n",
              "      <td>12703</td>\n",
              "      <td>https://i.ytimg.com/vi/1ZAPwfrtAFY/default.jpg</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>One year after the presidential election, John...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5qpjK5DgCt4</td>\n",
              "      <td>17.14.11</td>\n",
              "      <td>Racist Superman | Rudy Mancuso, King Bach &amp; Le...</td>\n",
              "      <td>Rudy Mancuso</td>\n",
              "      <td>Comedy</td>\n",
              "      <td>23</td>\n",
              "      <td>2017-11-12T19:05:24.000Z</td>\n",
              "      <td>racist superman|\"rudy\"|\"mancuso\"|\"king\"|\"bach\"...</td>\n",
              "      <td>3191434</td>\n",
              "      <td>146033</td>\n",
              "      <td>5339</td>\n",
              "      <td>8181</td>\n",
              "      <td>https://i.ytimg.com/vi/5qpjK5DgCt4/default.jpg</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>WATCH MY PREVIOUS VIDEO ▶ \\n\\nSUBSCRIBE ► http...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>puqaWrEC7tY</td>\n",
              "      <td>17.14.11</td>\n",
              "      <td>Nickelback Lyrics: Real or Fake?</td>\n",
              "      <td>Good Mythical Morning</td>\n",
              "      <td>Entertainment</td>\n",
              "      <td>24</td>\n",
              "      <td>2017-11-13T11:00:04.000Z</td>\n",
              "      <td>rhett and link|\"gmm\"|\"good mythical morning\"|\"...</td>\n",
              "      <td>343168</td>\n",
              "      <td>10172</td>\n",
              "      <td>666</td>\n",
              "      <td>2146</td>\n",
              "      <td>https://i.ytimg.com/vi/puqaWrEC7tY/default.jpg</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Today we find out if Link is a Nickelback amat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>d380meD0W0M</td>\n",
              "      <td>17.14.11</td>\n",
              "      <td>I Dare You: GOING BALD!?</td>\n",
              "      <td>nigahiga</td>\n",
              "      <td>Entertainment</td>\n",
              "      <td>24</td>\n",
              "      <td>2017-11-12T18:01:41.000Z</td>\n",
              "      <td>ryan|\"higa\"|\"higatv\"|\"nigahiga\"|\"i dare you\"|\"...</td>\n",
              "      <td>2095731</td>\n",
              "      <td>132235</td>\n",
              "      <td>1989</td>\n",
              "      <td>17518</td>\n",
              "      <td>https://i.ytimg.com/vi/d380meD0W0M/default.jpg</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>I know it's been a while since we did this sho...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      video_id  ...                                        description\n",
              "0  2kyS6SvSYSE  ...  SHANTELL'S CHANNEL - https://www.youtube.com/s...\n",
              "1  1ZAPwfrtAFY  ...  One year after the presidential election, John...\n",
              "2  5qpjK5DgCt4  ...  WATCH MY PREVIOUS VIDEO ▶ \\n\\nSUBSCRIBE ► http...\n",
              "3  puqaWrEC7tY  ...  Today we find out if Link is a Nickelback amat...\n",
              "4  d380meD0W0M  ...  I know it's been a while since we did this sho...\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbFjLgVvrUUS",
        "colab_type": "text"
      },
      "source": [
        "**Remove Duplicates**\n",
        "\n",
        "The outcome of this experiment will be heavily impacted by duplicate videos. For example, if there are duplicates, splitting the dataset into test and training data might result in the same video appearing in both sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjUaFboC_2b8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "videos.drop_duplicates(subset=\"title\", keep=\"last\", inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2Ztz0yB40dE",
        "colab_type": "text"
      },
      "source": [
        "**Creating New Attributes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRg4jzR5uKAR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "function: get_tags\n",
        "param(s): text, a string\n",
        "returns: a list of tokenized strings\n",
        "\"\"\"\n",
        "def get_tags(text):\n",
        "  # split text into list of words\n",
        "  data = re.split(\"\\\"| |\\|\", str(text))\n",
        "  return \" \".join(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxikGx0pufKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# a tfidf vectorizer takes care of this later on\n",
        "# videos['tags'] = videos['tags'].apply(get_tags)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p_lWRcRQv8D6",
        "colab": {}
      },
      "source": [
        "videos[\"likes_per_view\"] = videos[\"likes\"]/videos[\"views\"]\n",
        "videos[\"dislikes_per_view\"] = videos[\"dislikes\"]/videos[\"views\"]\n",
        "videos[\"comments_per_view\"] = videos[\"comment_count\"]/videos[\"views\"]\n",
        "\n",
        "videos[\"total_likes_dislikes\"] = videos[\"likes\"] + videos[\"dislikes\"]\n",
        "videos[\"total_likes_dislikes_per_view\"] = videos[\"total_likes_dislikes\"]/videos[\"views\"]\n",
        "\n",
        "videos[\"likes_percentage\"] = videos[\"likes\"]/videos[\"total_likes_dislikes\"]\n",
        "videos[\"dislikes_percentage\"] =videos[\"dislikes\"]/videos[\"total_likes_dislikes\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-bgc2MKxtNV",
        "colab_type": "text"
      },
      "source": [
        "The first classification task we are going to tackle is to classify videos by cateogory. We already saw in the Word2Vec sub-experiment that the gensim model did not do as well of a job learning word embeddings to categories. We will perform a similar experiment here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hOiK5t4yH6h",
        "colab_type": "code",
        "outputId": "de44eb41-9dea-45c8-8ec2-67fbc42b3d65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "source": [
        "videos['category'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Entertainment            1644\n",
              "Music                     821\n",
              "Howto & Style             601\n",
              "Comedy                    548\n",
              "News & Politics           510\n",
              "People & Blogs            502\n",
              "Sports                    455\n",
              "Science & Technology      391\n",
              "Film & Animation          322\n",
              "Education                 257\n",
              "Pets & Animals            144\n",
              "Gaming                    104\n",
              "Autos & Vehicles           73\n",
              "Travel & Events            64\n",
              "Nonprofits & Activism      15\n",
              "Shows                       4\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vD9agZOyMQg",
        "colab_type": "text"
      },
      "source": [
        "We can already see some issues - let's finish data preprocessing before tackling this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRe_yF7L9mul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# source https://www.kaggle.com/skalskip/youtube-data-exploration-and-plotly-visualization\n",
        "\n",
        "videos['trending_date'] = pd.to_datetime(videos['trending_date'], format='%y.%d.%m').dt.date\n",
        "reformatted_time = pd.to_datetime(videos['publish_time'], format='%Y-%m-%dT%H:%M:%S.%fZ')\n",
        "\n",
        "videos['publish_date'] = reformatted_time.dt.date\n",
        "videos['publish_time'] = reformatted_time.dt.time\n",
        "videos['publish_hour'] = reformatted_time.dt.hour\n",
        "videos['publish_month'] = reformatted_time.dt.month\n",
        "videos['publish_year'] = reformatted_time.dt.year"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZGGpPdr9uMn",
        "colab_type": "code",
        "outputId": "64aa2009-e1a1-4a84-cef0-50a4acaf6eb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        }
      },
      "source": [
        "videos['publish_year'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2018    4209\n",
              "2017    2176\n",
              "2013      13\n",
              "2015      10\n",
              "2016       9\n",
              "2011       8\n",
              "2012       8\n",
              "2014       7\n",
              "2010       6\n",
              "2009       5\n",
              "2008       3\n",
              "2006       1\n",
              "Name: publish_year, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcNDAvduxEW_",
        "colab_type": "text"
      },
      "source": [
        "For a later classification sub=experiment, I will classify videos by their year using natural language processing. To accomplish this I will use two labels: 2018 and pre-2018."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8M_zKKHDiny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "function: new_year_labels\n",
        "params: year, an integer\n",
        "returns: an integer (binary value [2017,2018])\n",
        "does: converts publish_year column to 2018 and pre-2018 values\n",
        "\"\"\"\n",
        "def new_year_labels(year):\n",
        "  if int(year) == 2018:\n",
        "    return '2018'\n",
        "  return '2017'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbqJVwcwDRFb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# assign new values to the year_classes column\n",
        "videos['year_classes'] = videos['publish_year'].apply(new_year_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbvJEHbfD7a0",
        "colab_type": "code",
        "outputId": "c60be884-504f-4d3a-f014-a5428c28ef1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "videos['year_classes'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2018    4209\n",
              "2017    2246\n",
              "Name: year_classes, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XkwgIKv8ipy",
        "colab_type": "text"
      },
      "source": [
        "**Testing and Metrics Function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oj5AGQxVa2u0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "function: plot_precision_recall\n",
        "params: precision, a float; recall, a float\n",
        "returns: nothing\n",
        "does: plots precision as a function of recall\n",
        "source: https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html\n",
        "\"\"\"\n",
        "def plot_precision_recall(precision, recall):\n",
        "  print('post')\n",
        "  step_kwargs = ({'step': 'post'}\n",
        "                if 'step' in signature(plt.fill_between).parameters\n",
        "                else {})\n",
        "\n",
        "  plt.step(recall, precision, color='b', alpha=0.2, where='post')\n",
        "  print('post2')\n",
        "  plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
        "  print('post3')\n",
        "  plt.xlabel('Recall')\n",
        "  plt.ylabel('Precision')\n",
        "  plt.ylim([0.0, 1.05])\n",
        "  plt.xlim([0.0, 1.0])\n",
        "  plt.title('2-class Precision-Recall curve:')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwoYkd8e1zd0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "function: test_model\n",
        "params: clf, a function; y_pred, a list; test_labels, a list\n",
        "returns: nothing\n",
        "does: prints out precision, recall, f-score, and ROC AUC\n",
        "\"\"\"\n",
        "def test_model(clf, y_pred, test_labels):\n",
        "  metrics = precision_recall_fscore_support(y_true=test_labels, y_pred=y_pred, average='weighted')\n",
        "  accuracy = accuracy_score(test_labels, y_pred, normalize=True)\n",
        "  print('Test Precision: %.5f' %metrics[0])\n",
        "  print('Test Recall: %.5f' %metrics[1])\n",
        "  print('Test F-Score: : %.5f' %metrics[2])\n",
        "  print('Test Accuracy: : %.5f' %accuracy)\n",
        "  # plot_precision_recall(metrics[0], metrics[1])\n",
        "  # auc = roc_auc_score(test_labels, clf.predict_proba(test_dataset['title'])[:,1])\n",
        "  # print('Test ROC AUC: %.5f' %auc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_3HgCE48EQE",
        "colab_type": "text"
      },
      "source": [
        "`FeatureUnion` combines two `TfidfVectorizers` to clean text for our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZonmlwAvIIx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizerW = TfidfVectorizer(lowercase=True, analyzer='word', stop_words=None, ngram_range = (1,1), max_df=1.0, min_df=1, max_features=None, norm = 'l2')\n",
        "vectorizerC = TfidfVectorizer(lowercase=True, analyzer='char', stop_words=None, ngram_range = (1,1), max_df=1.0, min_df=1, max_features=None, norm = 'l2')\n",
        "combined_features = FeatureUnion([('word', vectorizerW), ('char', vectorizerC)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usQKSpYSxw9v",
        "colab_type": "text"
      },
      "source": [
        "# Classify Video Category\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBbyTnj3yjnN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create training and testing sets\n",
        "train_dataset = videos.sample(frac=0.8,random_state=12345)\n",
        "test_dataset = videos.drop(train_dataset.index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpPnNw6iyrh4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# clean data\n",
        "train_dataset = train_dataset.dropna()\n",
        "test_dataset = test_dataset.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5vVMfKawBOE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get labels\n",
        "train_labels = train_dataset.pop('category')\n",
        "test_labels = test_dataset.pop('category')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDjCK0hItw4f",
        "colab_type": "code",
        "outputId": "2d95e709-a98f-4a54-869b-8d5771c57e6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# get lengths of train and test datasets\n",
        "print(train_dataset.shape[0])\n",
        "print(test_dataset.shape[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5051\n",
            "1269\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wR83gVoKy3QI",
        "colab_type": "text"
      },
      "source": [
        "Combine text columns into variables to be passed to models\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8Pv-FqiMKnh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combined_train = train_dataset['title'] + train_dataset['description'] + train_dataset['channel_title'] + train_dataset['tags']\n",
        "combined_test = test_dataset['title'] + test_dataset['description'] + test_dataset['channel_title'] + test_dataset['tags']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjWD8zap8o8p",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "**MultinomialNB (strawman)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gj3ABUmP62yV",
        "colab_type": "text"
      },
      "source": [
        "For our strawman model, we will use MultinomialNB to predict `cateogory` label for each example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNHLXLAy0nPF",
        "colab_type": "code",
        "outputId": "c288d994-3882-486b-8804-0a75a0d661ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "source": [
        "clf = Pipeline([\n",
        "    ('features', combined_features),\n",
        "    ('clf', MultinomialNB())\n",
        "    ])\n",
        "\n",
        "parameters = {'clf__alpha': (0, 0.5, 1),\n",
        "              'clf__fit_prior': (True, False)}\n",
        "\n",
        "clf = GridSearchCV(clf, parameters, cv=3, n_jobs =-1, verbose=1)\n",
        "\n",
        "clf = clf.fit(combined_train, train_labels)\n",
        "y_pred = clf.predict(combined_test)\n",
        "test_model(clf, y_pred, test_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:   33.0s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Precision: 0.79363\n",
            "Test Recall: 0.75965\n",
            "Test F-Score: : 0.75197\n",
            "Test Accuracy: : 0.75965\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iB1iEnL7BkO",
        "colab_type": "text"
      },
      "source": [
        "Test Precision: 0.79363\n",
        "\n",
        "Test Recall: 0.75965\n",
        "\n",
        "Test F-Score: : 0.75197\n",
        "\n",
        "Test Accuracy: : 0.75965\n",
        "\n",
        "Overall, the metrics are not great. There's plenty of room for improvement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wxban_5meD2m",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "\n",
        "**LogisticRegressionCV**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0o_WxVueGjF",
        "colab_type": "text"
      },
      "source": [
        "We can improve on the strawman by using logistic regression with cross validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSwMrkwzvJ4S",
        "colab_type": "code",
        "outputId": "7cb95083-104f-4683-e9c8-ea50715946d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "clf = Pipeline([\n",
        "    ('features', combined_features),\n",
        "    ('clf', LogisticRegressionCV(cv=10, solver='newton-cg', n_jobs=-1, multi_class='multinomial', verbose=1))\n",
        "    ])\n",
        "\n",
        "clf = clf.fit(combined_train, train_labels)\n",
        "y_pred = clf.predict(combined_test)\n",
        "test_model(clf, y_pred, test_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 3 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
            "  % (min_groups, self.n_splits)), Warning)\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 15.2min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Precision: 0.80415\n",
            "Test Recall: 0.80693\n",
            "Test F-Score: : 0.80102\n",
            "Test Accuracy: : 0.80693\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFyABRYxd3e4",
        "colab_type": "text"
      },
      "source": [
        "Test Precision: 0.80415\n",
        "\n",
        "Test Recall: 0.80693\n",
        "\n",
        "Test F-Score: : 0.80102\n",
        "\n",
        "Test Accuracy: : 0.80693"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2OSxC0d7mrT",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "\n",
        "**Aggregate Labels**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITlC787W7RVe",
        "colab_type": "text"
      },
      "source": [
        "Even though we got an accuracy of ~80%, that's still not good enough. We can do better. One of the problems we are running into is that there are not enough examples for each of the caterogies, even after smoothing is applied. Here are the values of our labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDo9DBvQym13",
        "colab_type": "code",
        "outputId": "0a4fe59e-0999-4601-d321-74a8af447769",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "source": [
        "train_labels.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Entertainment            1277\n",
              "Music                     639\n",
              "Howto & Style             476\n",
              "Comedy                    426\n",
              "News & Politics           404\n",
              "People & Blogs            386\n",
              "Sports                    353\n",
              "Science & Technology      308\n",
              "Film & Animation          260\n",
              "Education                 204\n",
              "Pets & Animals            117\n",
              "Gaming                     83\n",
              "Autos & Vehicles           53\n",
              "Travel & Events            52\n",
              "Nonprofits & Activism      10\n",
              "Shows                       3\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_8UinRRzIgg",
        "colab_type": "text"
      },
      "source": [
        "Some of these values are high in number, while others are pretty low (less than 100 examples). We do not have enough examples, even after smoothing is performed. There's simply too many categories to perform classification. We need to reduce the number of classes to get a better result. Let us aggregate attributes.\n",
        "\n",
        "**New Labels**\n",
        "\n",
        "I will redefine the given labels as a binary classification problem using the labels `Entertainment` and `Informational`. Given the labels, it is easy to see that these two labels encompass the entirety of the classes.\n",
        "\n",
        "`Entertainment` = `Entertainment` + `Music` + `Comedy` + `Film & Animation` + `Gaming` + `Shows` + `Pets & Animals`\n",
        "\n",
        "`Informational` = `News & Politics` + `Nonpofits & Activism` + `Education` + `Travel & Events` + `Science & Technology` + `Autos & Vehicles` + `Howto & Style` + `People & Blogs` + `Sports`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHJq2Wg4wSD4",
        "colab_type": "text"
      },
      "source": [
        "**Create New Labels Function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyZQNzkUe7Gj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "function: create_new_labels\n",
        "params: label, a string\n",
        "returns: a new label\n",
        "does: aggregates labels for the YouTube top daily trending videos dataset into \n",
        "      new categories\n",
        "\"\"\"\n",
        "def create_new_labels(label):\n",
        "  label = str(label)\n",
        "  if label=='Music' or label=='Comedy' or label=='Gaming' or label=='Shows' \\\n",
        "  or label=='Film & Animation' or label=='Pets & Animals' \\\n",
        "  or label=='Entertainment':\n",
        "    return 'Other Entertainment'\n",
        "  elif label=='People & Blogs' or label=='Education' \\\n",
        "  or label=='Nonprofits & Activism' or label=='Travel & Events' \\\n",
        "  or label=='Autos & Vehicles' or label=='Science & Technology' \\\n",
        "  or label=='Howto & Style' or label=='News & Politics' or label=='Sports':\n",
        "    return 'Informational'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blLp5_Bwgyll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels = train_labels.apply(create_new_labels)\n",
        "test_labels = test_labels.apply(create_new_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enTnw4C_n0Vz",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "**BernoulliNB with New Labels**\n",
        "\n",
        "We need to verify that our strawman model improves with this binary distirbution of the category label. Note that we are now using a bernoulli distribution instead of multinomial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDksxGsCg-ci",
        "colab_type": "code",
        "outputId": "acbe86f9-f003-4a39-956b-224ad25fa292",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "train_labels.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Other Entertainment    2805\n",
              "Informational          2246\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ5pbheem7VZ",
        "colab_type": "code",
        "outputId": "a7ccaa22-92e6-4eab-f311-01ad53f07add",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "clf = Pipeline([\n",
        "    ('features', combined_features),\n",
        "    ('clf', BernoulliNB())\n",
        "    ])\n",
        "\n",
        "parameters = {'clf__alpha': (0, 0.5, 1),\n",
        "              'clf__fit_prior': (True, False)}\n",
        "\n",
        "clf = GridSearchCV(clf, parameters, cv=3, n_jobs =-1, verbose=1)\n",
        "\n",
        "clf = clf.fit(combined_train, train_labels)\n",
        "y_pred = clf.predict(combined_test)\n",
        "test_model(clf, y_pred, test_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:   32.6s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Precision: 0.90533\n",
            "Test Recall: 0.90544\n",
            "Test F-Score: : 0.90527\n",
            "Test Accuracy: : 0.90544\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDet4IKlwe_5",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "\n",
        "**LogisticRegressionCV with New Labels**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6AHXLj08PMJ",
        "colab_type": "text"
      },
      "source": [
        "Next, we test a model. We choose `LogisticRegressionCV`, this time we can increase cross validation to 10 fold given that we have more instances of each class label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wE2Jx3GtEuO",
        "colab_type": "code",
        "outputId": "23cdd0de-a46b-4323-ff9b-f6ea56fe086c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "clf = Pipeline([\n",
        "    ('features', combined_features),\n",
        "    ('clf', LogisticRegressionCV(cv=10, n_jobs=-1, verbose=1))\n",
        "    ])\n",
        "\n",
        "clf = clf.fit(combined_train, train_labels)\n",
        "y_pred = clf.predict(combined_test)\n",
        "test_model(clf, y_pred, test_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   45.6s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Precision: 0.90614\n",
            "Test Recall: 0.90623\n",
            "Test F-Score: : 0.90617\n",
            "Test Accuracy: : 0.90623\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAuh1TpxkArO",
        "colab_type": "text"
      },
      "source": [
        "Test Precision: 0.91006\n",
        "\n",
        "Test Recall: 0.91017\n",
        "\n",
        "Test F-Score: : 0.91003\n",
        "\n",
        "Test Accuracy: : 0.91017"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYoaFeA0rRW5",
        "colab_type": "text"
      },
      "source": [
        "**Conclusion**\n",
        "\n",
        "We can now see that given an aggregation of labels to a binary distribution, we are can easily predict the type of video it is. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Arc-XUhKFPHi",
        "colab_type": "text"
      },
      "source": [
        "# Classify Video Publishing Year\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e5tSjAWzLAg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create training and testing sets\n",
        "train_dataset = videos.sample(frac=0.8,random_state=12345)\n",
        "test_dataset = videos.drop(train_dataset.index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhiVedh9zLMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# clean the data\n",
        "train_dataset = train_dataset.dropna()\n",
        "test_dataset = test_dataset.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bRcaRgbFOUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get labels\n",
        "train_labels = train_dataset.pop('year_classes')\n",
        "test_labels = test_dataset.pop('year_classes')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiGulcxedV3k",
        "colab_type": "code",
        "outputId": "67f0f3d5-4353-4e5e-97ce-bdd983692911",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# get lengths of train and test datasets\n",
        "print(train_dataset.shape[0])\n",
        "print(test_dataset.shape[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5051\n",
            "1269\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpzjgaSqzd1M",
        "colab_type": "text"
      },
      "source": [
        "Combine text columns into variables to be passed to models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7rM5DDJcFEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combined_train = train_dataset['title'] + train_dataset['description'] + train_dataset['channel_title'] + train_dataset['tags']\n",
        "combined_test = test_dataset['title'] + test_dataset['description'] + test_dataset['channel_title'] + test_dataset['tags']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQ7tXzPnFqsD",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "\n",
        "**BernoulliNB (strawman model)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjCc9agyFhhH",
        "colab_type": "code",
        "outputId": "4416e2d3-29de-492c-dfb1-a7b639206891",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        }
      },
      "source": [
        "clf = Pipeline([\n",
        "    ('features', combined_features),\n",
        "    ('clf', BernoulliNB())\n",
        "    ])\n",
        "\n",
        "parameters = {'clf__alpha': (0, 0.5, 1),\n",
        "              'clf__fit_prior': (True, False)}\n",
        "\n",
        "clf = GridSearchCV(clf, parameters, cv=10, n_jobs =-1, verbose=1)\n",
        "\n",
        "clf = clf.fit(combined_train, train_labels)\n",
        "y_pred = clf.predict(combined_test)\n",
        "test_model(clf, y_pred, test_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  1.3min\n",
            "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  1.7min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Precision: 0.71486\n",
            "Test Recall: 0.72656\n",
            "Test F-Score: : 0.71502\n",
            "Test Accuracy: : 0.72656\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQP-M-IFGSCF",
        "colab_type": "text"
      },
      "source": [
        "Test Precision: 0.71486\n",
        "\n",
        "Test Recall: 0.72656\n",
        "\n",
        "Test F-Score: : 0.71502\n",
        "\n",
        "Test Accuracy: : 0.72656"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gB9GzDRkJM6C",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "\n",
        "**LogisticRegressionCV (n=10)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NHRISh0IojU",
        "colab_type": "code",
        "outputId": "45ec0cf9-e3da-4332-fab1-4d855dd321f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "clf = Pipeline([\n",
        "    ('features', combined_features),\n",
        "    ('clf', LogisticRegressionCV(cv=10, solver='liblinear', n_jobs=-1, verbose=1))\n",
        "])\n",
        "\n",
        "# vectorizer = HashingVectorizer()\n",
        "# combined_train = vectorizer.fit_transform(combined_train)\n",
        "clf = clf.fit(combined_train, train_labels)\n",
        "y_pred = clf.predict(combined_test)\n",
        "test_model(clf, y_pred, test_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   24.8s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Precision: 0.76914\n",
            "Test Recall: 0.77541\n",
            "Test F-Score: : 0.76616\n",
            "Test Accuracy: : 0.77541\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cA2qxwRJhJm",
        "colab_type": "text"
      },
      "source": [
        "Test Precision: 0.76914\n",
        "\n",
        "Test Recall: 0.77541\n",
        "\n",
        "Test F-Score: : 0.76616\n",
        "\n",
        "Test Accuracy: : 0.77541"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X64LZab5JSE7",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "\n",
        "**MLPClassifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dtt7eGKGA6K",
        "colab_type": "code",
        "outputId": "5d430b2c-80c2-448a-cc30-d92d60cf56a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 823
        }
      },
      "source": [
        "clf = Pipeline([\n",
        "    ('features', combined_features),\n",
        "    ('clf', MLPClassifier(hidden_layer_sizes=(250, 150, 50), max_iter=100, \n",
        "                          activation='relu', random_state=12345, \n",
        "                          validation_fraction=0.2, verbose=True,\n",
        "                          early_stopping=True, warm_start=True, solver='adam'))\n",
        "])\n",
        "\n",
        "clf = clf.fit(combined_train, train_labels)\n",
        "y_pred = clf.predict(combined_test)\n",
        "test_model(clf, y_pred, test_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.65653214\n",
            "Validation score: 0.650841\n",
            "Iteration 2, loss = 0.57305160\n",
            "Validation score: 0.650841\n",
            "Iteration 3, loss = 0.36430651\n",
            "Validation score: 0.715134\n",
            "Iteration 4, loss = 0.13196476\n",
            "Validation score: 0.712166\n",
            "Iteration 5, loss = 0.03953167\n",
            "Validation score: 0.716123\n",
            "Iteration 6, loss = 0.02058556\n",
            "Validation score: 0.712166\n",
            "Iteration 7, loss = 0.01179413\n",
            "Validation score: 0.701286\n",
            "Iteration 8, loss = 0.00963031\n",
            "Validation score: 0.701286\n",
            "Iteration 9, loss = 0.00834186\n",
            "Validation score: 0.719090\n",
            "Iteration 10, loss = 0.00664469\n",
            "Validation score: 0.704253\n",
            "Iteration 11, loss = 0.00653145\n",
            "Validation score: 0.710188\n",
            "Iteration 12, loss = 0.00743982\n",
            "Validation score: 0.709199\n",
            "Iteration 13, loss = 0.00365423\n",
            "Validation score: 0.710188\n",
            "Iteration 14, loss = 0.01001386\n",
            "Validation score: 0.686449\n",
            "Iteration 15, loss = 0.01561804\n",
            "Validation score: 0.694362\n",
            "Iteration 16, loss = 0.01206586\n",
            "Validation score: 0.688427\n",
            "Iteration 17, loss = 0.00898524\n",
            "Validation score: 0.714144\n",
            "Iteration 18, loss = 0.00732700\n",
            "Validation score: 0.694362\n",
            "Iteration 19, loss = 0.00648957\n",
            "Validation score: 0.695351\n",
            "Iteration 20, loss = 0.00572250\n",
            "Validation score: 0.714144\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Test Precision: 0.74145\n",
            "Test Recall: 0.74783\n",
            "Test F-Score: : 0.72681\n",
            "Test Accuracy: : 0.74783\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6t-BKKsMD1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYdKK6JEMEFl",
        "colab_type": "text"
      },
      "source": [
        "Test Precision: 0.74145\n",
        "\n",
        "Test Recall: 0.74783\n",
        "\n",
        "Test F-Score: : 0.72681\n",
        "\n",
        "Test Accuracy: : 0.74783"
      ]
    }
  ]
}