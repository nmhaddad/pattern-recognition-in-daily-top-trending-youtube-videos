{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "youtube_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OTkkR7civapF"
      },
      "source": [
        "# Pattern Recognition in Daily Top Trending YouTube Videos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bt1--m2cVOBq",
        "colab_type": "text"
      },
      "source": [
        "## NLP Classification Sub-Experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y60Bbpnmt79y"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LJwVvfc_yKtR",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from google.colab import drive\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.pipeline import FeatureUnion\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SM5f7pz99U4K"
      },
      "source": [
        "**Load Data From Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bma2ZWaPkKen",
        "outputId": "239b6d7c-0930-4407-c265-09017321e169",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8Qf7kT6_9ejN"
      },
      "source": [
        "**Read-in CSV & JSON**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "36cOy5BrkVhQ",
        "colab": {}
      },
      "source": [
        "videos = pd.read_csv(\"/content/drive/My Drive/cs6140 project/data/USvideos.csv\")\n",
        "videos_categories = pd.read_json(\"/content/drive/My Drive/cs6140 project/data/US_category_id.json\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UgB67Ybi_JqP"
      },
      "source": [
        "This block of code links the csv to json categories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DC8UI5RhjQoc",
        "colab": {}
      },
      "source": [
        "# source: https://www.kaggle.com/skalskip/youtube-data-exploration-and-plotly-visualization\n",
        "categories = {category['id']: category['snippet']['title'] for category in videos_categories['items']}\n",
        "videos.insert(4, 'category', videos['category_id'].astype(str).map(categories))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UKSLE5f5tl2g",
        "outputId": "13c9bd66-8274-4307-e183-853e88f73369",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "videos.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_id</th>\n",
              "      <th>trending_date</th>\n",
              "      <th>title</th>\n",
              "      <th>channel_title</th>\n",
              "      <th>category</th>\n",
              "      <th>category_id</th>\n",
              "      <th>publish_time</th>\n",
              "      <th>tags</th>\n",
              "      <th>views</th>\n",
              "      <th>likes</th>\n",
              "      <th>dislikes</th>\n",
              "      <th>comment_count</th>\n",
              "      <th>thumbnail_link</th>\n",
              "      <th>comments_disabled</th>\n",
              "      <th>ratings_disabled</th>\n",
              "      <th>video_error_or_removed</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2kyS6SvSYSE</td>\n",
              "      <td>17.14.11</td>\n",
              "      <td>WE WANT TO TALK ABOUT OUR MARRIAGE</td>\n",
              "      <td>CaseyNeistat</td>\n",
              "      <td>People &amp; Blogs</td>\n",
              "      <td>22</td>\n",
              "      <td>2017-11-13T17:13:01.000Z</td>\n",
              "      <td>SHANtell martin</td>\n",
              "      <td>748374</td>\n",
              "      <td>57527</td>\n",
              "      <td>2966</td>\n",
              "      <td>15954</td>\n",
              "      <td>https://i.ytimg.com/vi/2kyS6SvSYSE/default.jpg</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>SHANTELL'S CHANNEL - https://www.youtube.com/s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1ZAPwfrtAFY</td>\n",
              "      <td>17.14.11</td>\n",
              "      <td>The Trump Presidency: Last Week Tonight with J...</td>\n",
              "      <td>LastWeekTonight</td>\n",
              "      <td>Entertainment</td>\n",
              "      <td>24</td>\n",
              "      <td>2017-11-13T07:30:00.000Z</td>\n",
              "      <td>last week tonight trump presidency|\"last week ...</td>\n",
              "      <td>2418783</td>\n",
              "      <td>97185</td>\n",
              "      <td>6146</td>\n",
              "      <td>12703</td>\n",
              "      <td>https://i.ytimg.com/vi/1ZAPwfrtAFY/default.jpg</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>One year after the presidential election, John...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5qpjK5DgCt4</td>\n",
              "      <td>17.14.11</td>\n",
              "      <td>Racist Superman | Rudy Mancuso, King Bach &amp; Le...</td>\n",
              "      <td>Rudy Mancuso</td>\n",
              "      <td>Comedy</td>\n",
              "      <td>23</td>\n",
              "      <td>2017-11-12T19:05:24.000Z</td>\n",
              "      <td>racist superman|\"rudy\"|\"mancuso\"|\"king\"|\"bach\"...</td>\n",
              "      <td>3191434</td>\n",
              "      <td>146033</td>\n",
              "      <td>5339</td>\n",
              "      <td>8181</td>\n",
              "      <td>https://i.ytimg.com/vi/5qpjK5DgCt4/default.jpg</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>WATCH MY PREVIOUS VIDEO ▶ \\n\\nSUBSCRIBE ► http...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>puqaWrEC7tY</td>\n",
              "      <td>17.14.11</td>\n",
              "      <td>Nickelback Lyrics: Real or Fake?</td>\n",
              "      <td>Good Mythical Morning</td>\n",
              "      <td>Entertainment</td>\n",
              "      <td>24</td>\n",
              "      <td>2017-11-13T11:00:04.000Z</td>\n",
              "      <td>rhett and link|\"gmm\"|\"good mythical morning\"|\"...</td>\n",
              "      <td>343168</td>\n",
              "      <td>10172</td>\n",
              "      <td>666</td>\n",
              "      <td>2146</td>\n",
              "      <td>https://i.ytimg.com/vi/puqaWrEC7tY/default.jpg</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Today we find out if Link is a Nickelback amat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>d380meD0W0M</td>\n",
              "      <td>17.14.11</td>\n",
              "      <td>I Dare You: GOING BALD!?</td>\n",
              "      <td>nigahiga</td>\n",
              "      <td>Entertainment</td>\n",
              "      <td>24</td>\n",
              "      <td>2017-11-12T18:01:41.000Z</td>\n",
              "      <td>ryan|\"higa\"|\"higatv\"|\"nigahiga\"|\"i dare you\"|\"...</td>\n",
              "      <td>2095731</td>\n",
              "      <td>132235</td>\n",
              "      <td>1989</td>\n",
              "      <td>17518</td>\n",
              "      <td>https://i.ytimg.com/vi/d380meD0W0M/default.jpg</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>I know it's been a while since we did this sho...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      video_id  ...                                        description\n",
              "0  2kyS6SvSYSE  ...  SHANTELL'S CHANNEL - https://www.youtube.com/s...\n",
              "1  1ZAPwfrtAFY  ...  One year after the presidential election, John...\n",
              "2  5qpjK5DgCt4  ...  WATCH MY PREVIOUS VIDEO ▶ \\n\\nSUBSCRIBE ► http...\n",
              "3  puqaWrEC7tY  ...  Today we find out if Link is a Nickelback amat...\n",
              "4  d380meD0W0M  ...  I know it's been a while since we did this sho...\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HbFjLgVvrUUS"
      },
      "source": [
        "**Remove Duplicates**\n",
        "\n",
        "The outcome of this experiment will be heavily impacted by duplicate videos. For example, if there are duplicates, splitting the dataset into test and training data might result in the same video appearing in both sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zjUaFboC_2b8",
        "colab": {}
      },
      "source": [
        "videos.drop_duplicates(subset=\"title\", keep=\"last\", inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Z2Ztz0yB40dE"
      },
      "source": [
        "**Creating New Attributes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VRg4jzR5uKAR",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "function: get_tags\n",
        "param(s): text, a string\n",
        "returns: a list of tokenized strings\n",
        "\"\"\"\n",
        "def get_tags(text):\n",
        "  # split text into list of words\n",
        "  data = re.split(\"\\\"| |\\|\", str(text))\n",
        "  return \" \".join(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AxikGx0pufKW",
        "colab": {}
      },
      "source": [
        "# a tfidf vectorizer takes care of this later on\n",
        "# videos['tags'] = videos['tags'].apply(get_tags)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p_lWRcRQv8D6",
        "colab": {}
      },
      "source": [
        "# rate of likes per view\n",
        "videos[\"likes_per_view\"] = videos[\"likes\"]/videos[\"views\"]\n",
        "# rate of dislikes per view\n",
        "videos[\"dislikes_per_view\"] = videos[\"dislikes\"]/videos[\"views\"]\n",
        "# rate of comments per view\n",
        "videos[\"comments_per_view\"] = videos[\"comment_count\"]/videos[\"views\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvhlYfdVPh9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "videos[\"total_likes_dislikes\"] = videos[\"likes\"] + videos[\"dislikes\"]\n",
        "videos[\"total_likes_dislikes_per_view\"] = videos[\"total_likes_dislikes\"]/videos[\"views\"]\n",
        "videos[\"likes_percentage\"] = videos[\"likes\"]/videos[\"total_likes_dislikes\"]\n",
        "videos[\"dislikes_percentage\"] =videos[\"dislikes\"]/videos[\"total_likes_dislikes\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7hOiK5t4yH6h",
        "outputId": "e39789ec-c181-4cb8-b4ce-dce6dd872e88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "videos['category'].value_counts()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Entertainment            1644\n",
              "Music                     821\n",
              "Howto & Style             601\n",
              "Comedy                    548\n",
              "News & Politics           510\n",
              "People & Blogs            502\n",
              "Sports                    455\n",
              "Science & Technology      391\n",
              "Film & Animation          322\n",
              "Education                 257\n",
              "Pets & Animals            144\n",
              "Gaming                    104\n",
              "Autos & Vehicles           73\n",
              "Travel & Events            64\n",
              "Nonprofits & Activism      15\n",
              "Shows                       4\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4vD9agZOyMQg"
      },
      "source": [
        "We can already see some issues - let's finish data preprocessing before tackling this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oRe_yF7L9mul",
        "colab": {}
      },
      "source": [
        "# source https://www.kaggle.com/skalskip/youtube-data-exploration-and-plotly-visualization\n",
        "\n",
        "videos['trending_date'] = pd.to_datetime(videos['trending_date'], format='%y.%d.%m').dt.date\n",
        "reformatted_time = pd.to_datetime(videos['publish_time'], format='%Y-%m-%dT%H:%M:%S.%fZ')\n",
        "\n",
        "videos['publish_date'] = reformatted_time.dt.date\n",
        "videos['publish_time'] = reformatted_time.dt.time\n",
        "videos['publish_hour'] = reformatted_time.dt.hour\n",
        "videos['publish_month'] = reformatted_time.dt.month\n",
        "videos['publish_year'] = reformatted_time.dt.year"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rZGGpPdr9uMn",
        "outputId": "44799809-a23f-4ac2-e6c8-e5de0bb0cc8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "videos['publish_year'].value_counts()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2018    4209\n",
              "2017    2176\n",
              "2013      13\n",
              "2015      10\n",
              "2016       9\n",
              "2011       8\n",
              "2012       8\n",
              "2014       7\n",
              "2010       6\n",
              "2009       5\n",
              "2008       3\n",
              "2006       1\n",
              "Name: publish_year, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WcNDAvduxEW_"
      },
      "source": [
        "For a later classification sub=experiment, I will classify videos by their year using natural language processing. To accomplish this I will use two labels: 2018 and pre-2018."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_8M_zKKHDiny",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "function: new_year_labels\n",
        "params: year, an integer\n",
        "returns: an integer (binary value [2017,2018])\n",
        "does: converts publish_year column to 2018 and pre-2018 values\n",
        "\"\"\"\n",
        "def new_year_labels(year):\n",
        "  if int(year) == 2018:\n",
        "    return '2018'\n",
        "  return '2017'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pbqJVwcwDRFb",
        "colab": {}
      },
      "source": [
        "# assign new values to the year_classes column\n",
        "videos['year_classes'] = videos['publish_year'].apply(new_year_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rbvJEHbfD7a0",
        "outputId": "b3870093-bee2-49c7-db5a-8dc2d6903347",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "videos['year_classes'].value_counts()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2018    4209\n",
              "2017    2246\n",
              "Name: year_classes, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1XkwgIKv8ipy"
      },
      "source": [
        "**Testing and Metrics Function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hwoYkd8e1zd0",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "function: test_model\n",
        "params: clf, a function; y_pred, a list; test_labels, a list\n",
        "returns: nothing\n",
        "does: prints out precision, recall, f-score, and ROC AUC\n",
        "\"\"\"\n",
        "def test_model(clf, y_pred, test_labels):\n",
        "  metrics = precision_recall_fscore_support(y_true=test_labels, \n",
        "                                            y_pred=y_pred, \n",
        "                                            average='weighted')\n",
        "  print('Test Precision: %.4f' %metrics[0])\n",
        "  print('Test Recall: %.4f' %metrics[1])\n",
        "  print('Test F-Score: : %.4f' %metrics[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sBLGPKvY43B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to keep output less verbose and ignore deprication and other warnings\n",
        "# source: https://stackoverflow.com/questions/32612180/eliminating-warnings-from-scikit-learn\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Z_3HgCE48EQE"
      },
      "source": [
        "`FeatureUnion` combines two `TfidfVectorizers` to clean text for our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WZonmlwAvIIx",
        "colab": {}
      },
      "source": [
        "vec_W = TfidfVectorizer(lowercase=True, \n",
        "                        analyzer='word',\n",
        "                        stop_words=None, \n",
        "                        ngram_range = (1,1), \n",
        "                        max_df=1.0, min_df=1, \n",
        "                        max_features=None, \n",
        "                        norm = 'l2')\n",
        "vec_C = TfidfVectorizer(lowercase=True, \n",
        "                        analyzer='char', \n",
        "                        stop_words=None, \n",
        "                        ngram_range = (1,1), \n",
        "                        max_df=1.0, min_df=1, \n",
        "                        max_features=None, \n",
        "                        norm = 'l2')\n",
        "\n",
        "combined_features = FeatureUnion([('word', vec_W), ('char', vec_C)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "usQKSpYSxw9v"
      },
      "source": [
        "## Classify Video Category"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZBbyTnj3yjnN",
        "colab": {}
      },
      "source": [
        "# create training and testing sets\n",
        "train_dataset = videos.sample(frac=0.8,random_state=12345)\n",
        "test_dataset = videos.drop(train_dataset.index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bpPnNw6iyrh4",
        "colab": {}
      },
      "source": [
        "# clean data\n",
        "train_dataset = train_dataset.dropna()\n",
        "test_dataset = test_dataset.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B5vVMfKawBOE",
        "colab": {}
      },
      "source": [
        "# get labels\n",
        "train_labels = train_dataset.pop('category')\n",
        "test_labels = test_dataset.pop('category')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JDjCK0hItw4f",
        "outputId": "874562ea-5719-4636-e71f-41f37c88748b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# get lengths of train and test datasets\n",
        "print(train_dataset.shape[0])\n",
        "print(test_dataset.shape[0])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5051\n",
            "1269\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wR83gVoKy3QI"
      },
      "source": [
        "Combine text columns into variables to be passed to models\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w8Pv-FqiMKnh",
        "colab": {}
      },
      "source": [
        "combined_train = train_dataset['title'] + train_dataset['description'] + train_dataset['channel_title'] + train_dataset['tags']\n",
        "combined_test = test_dataset['title'] + test_dataset['description'] + test_dataset['channel_title'] + test_dataset['tags']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OjWD8zap8o8p"
      },
      "source": [
        "**MultinomialNB (strawman)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gj3ABUmP62yV"
      },
      "source": [
        "For our strawman model, we will use MultinomialNB to predict `cateogory` label for each example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oNHLXLAy0nPF",
        "outputId": "cfb3b71d-b23c-4701-f6f4-06ffb34e5cb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "clf = Pipeline([\n",
        "    ('features', combined_features),\n",
        "    ('clf', MultinomialNB())\n",
        "    ])\n",
        "\n",
        "parameters = {'clf__alpha': (0, 1, 2),\n",
        "              'clf__fit_prior': (True, False)}\n",
        "\n",
        "clf = GridSearchCV(clf, parameters, cv=3)\n",
        "\n",
        "clf = clf.fit(combined_train, train_labels)\n",
        "y_pred = clf.predict(combined_test)\n",
        "test_model(clf, y_pred, test_labels)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Precision: 0.7936\n",
            "Test Recall: 0.7597\n",
            "Test F-Score: : 0.7520\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Wxban_5meD2m"
      },
      "source": [
        "**LogisticRegressionCV**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RSwMrkwzvJ4S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f746ef24-ffca-4bf2-e38c-f9f373e8f2e5"
      },
      "source": [
        "clf = Pipeline([\n",
        "    ('features', combined_features),\n",
        "    ('clf', LogisticRegressionCV(cv=3, solver='newton-cg', multi_class='multinomial'))\n",
        "    ])\n",
        "\n",
        "clf = clf.fit(combined_train, train_labels)\n",
        "y_pred = clf.predict(combined_test)\n",
        "test_model(clf, y_pred, test_labels)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Precision: 0.8027\n",
            "Test Recall: 0.8054\n",
            "Test F-Score: : 0.7994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s2OSxC0d7mrT"
      },
      "source": [
        "**Aggregate Labels**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ITlC787W7RVe"
      },
      "source": [
        "Even though we got an accuracy of ~80%, that's still not good enough. We can do better. One of the problems we are running into is that there are not enough examples for each of the caterogies, even after smoothing is applied. Here are the values of our labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sDo9DBvQym13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "94f86dd9-f780-4014-bd25-6a965071b599"
      },
      "source": [
        "train_labels.value_counts()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Entertainment            1277\n",
              "Music                     639\n",
              "Howto & Style             476\n",
              "Comedy                    426\n",
              "News & Politics           404\n",
              "People & Blogs            386\n",
              "Sports                    353\n",
              "Science & Technology      308\n",
              "Film & Animation          260\n",
              "Education                 204\n",
              "Pets & Animals            117\n",
              "Gaming                     83\n",
              "Autos & Vehicles           53\n",
              "Travel & Events            52\n",
              "Nonprofits & Activism      10\n",
              "Shows                       3\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m_8UinRRzIgg"
      },
      "source": [
        "Some of these values are high in number, while others are pretty low (less than 100 examples). We do not have enough examples, even after smoothing is performed. There's simply too many categories to perform classification. We need to reduce the number of classes to get a better result. Let us aggregate attributes.\n",
        "\n",
        "**New Labels**\n",
        "\n",
        "I will redefine the given labels as a binary classification problem using the labels `Entertainment` and `Informational`. Given the labels, it is easy to see that these two labels encompass the entirety of the classes.\n",
        "\n",
        "`Entertainment` = `Entertainment` + `Music` + `Comedy` + `Film & Animation` + `Gaming` + `Shows` + `Pets & Animals`\n",
        "\n",
        "`Informational` = `News & Politics` + `Nonpofits & Activism` + `Education` + `Travel & Events` + `Science & Technology` + `Autos & Vehicles` + `Howto & Style` + `People & Blogs` + `Sports`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oHJq2Wg4wSD4"
      },
      "source": [
        "**Create New Labels Function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YyZQNzkUe7Gj",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "function: create_new_labels\n",
        "params: label, a string\n",
        "returns: a new label\n",
        "does: aggregates labels for the YouTube top daily trending videos dataset into \n",
        "      new categories\n",
        "\"\"\"\n",
        "def create_new_labels(label):\n",
        "    if str(label) in ['Music', 'Comedy', 'Gaming', 'Shows', 'Film & Animation', 'Pets & Animals', 'Entertainment']:\n",
        "        return 'Other Entertainment'\n",
        "    elif str(label) in ['People & Blogs', 'Education', 'Nonprofits & Activism', 'Travel & Events', \n",
        "                        'Autos & Vehicles', 'Science & Technology','Howto & Style', 'News & Politics', 'Sports']:\n",
        "        return 'Informational'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "blLp5_Bwgyll",
        "colab": {}
      },
      "source": [
        "train_labels = train_labels.apply(create_new_labels)\n",
        "test_labels = test_labels.apply(create_new_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "enTnw4C_n0Vz"
      },
      "source": [
        "**BernoulliNB with New Labels**\n",
        "\n",
        "We need to verify that our strawman model improves with this binary distirbution of the category label. Note that we are now using a bernoulli distribution instead of multinomial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hDksxGsCg-ci",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9e0c3ed8-911d-4278-e8e2-58c18d3fc1cb"
      },
      "source": [
        "train_labels.value_counts()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Other Entertainment    2805\n",
              "Informational          2246\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zQ5pbheem7VZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e004dec7-243b-4bf0-9987-8951f0b09d47"
      },
      "source": [
        "clf = Pipeline([\n",
        "    ('features', combined_features),\n",
        "    ('clf', BernoulliNB())\n",
        "    ])\n",
        "\n",
        "parameters = {'clf__alpha': (0.5, 0.5, 1),\n",
        "              'clf__fit_prior': (True, False)}\n",
        "\n",
        "clf = GridSearchCV(clf, parameters, cv=3)\n",
        "\n",
        "clf = clf.fit(combined_train, train_labels)\n",
        "y_pred = clf.predict(combined_test)\n",
        "test_model(clf, y_pred, test_labels)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Precision: 0.9040\n",
            "Test Recall: 0.9039\n",
            "Test F-Score: : 0.9035\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wDet4IKlwe_5"
      },
      "source": [
        "**LogisticRegressionCV with New Labels**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m6AHXLj08PMJ"
      },
      "source": [
        "Next, we test a model. We choose `LogisticRegressionCV`, this time we can increase cross validation to 10 fold given that we have more instances of each class label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_wE2Jx3GtEuO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "4a626908-e3b2-4bce-9583-2ee036784c45"
      },
      "source": [
        "clf = Pipeline([\n",
        "    ('features', combined_features),\n",
        "    ('clf', LogisticRegressionCV(cv=3))\n",
        "    ])\n",
        "\n",
        "clf = clf.fit(combined_train, train_labels)\n",
        "y_pred = clf.predict(combined_test)\n",
        "test_model(clf, y_pred, test_labels)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Precision: 0.9077\n",
            "Test Recall: 0.9078\n",
            "Test F-Score: : 0.9077\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BYoaFeA0rRW5"
      },
      "source": [
        "**Conclusion**\n",
        "\n",
        "We can now see that given an aggregation of labels to a binary distribution, we are can easily predict the type of video it is. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Arc-XUhKFPHi"
      },
      "source": [
        "## Classify Video Publishing Year"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6e5tSjAWzLAg",
        "colab": {}
      },
      "source": [
        "# create training and testing sets\n",
        "train_dataset = videos.sample(frac=0.8,random_state=42)\n",
        "test_dataset = videos.drop(train_dataset.index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JhiVedh9zLMk",
        "colab": {}
      },
      "source": [
        "# clean the data\n",
        "train_dataset = train_dataset.dropna()\n",
        "test_dataset = test_dataset.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6bRcaRgbFOUA",
        "colab": {}
      },
      "source": [
        "# get labels\n",
        "train_labels = train_dataset.pop('year_classes')\n",
        "test_labels = test_dataset.pop('year_classes')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hiGulcxedV3k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "963feefa-289b-4eca-b20e-15200b64ee31"
      },
      "source": [
        "print(train_dataset.shape[0])\n",
        "print(test_dataset.shape[0])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5059\n",
            "1261\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JpzjgaSqzd1M"
      },
      "source": [
        "Combine text columns into variables to be passed to models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n7rM5DDJcFEj",
        "colab": {}
      },
      "source": [
        "combined_train = train_dataset['title'] + train_dataset['description'] + train_dataset['channel_title'] + train_dataset['tags']\n",
        "combined_test = test_dataset['title'] + test_dataset['description'] + test_dataset['channel_title'] + test_dataset['tags']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RQ7tXzPnFqsD"
      },
      "source": [
        "**BernoulliNB (strawman model)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OjCc9agyFhhH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6c83e7a2-7ba4-4ff9-8c3a-e7e5c6a64ee9"
      },
      "source": [
        "clf = Pipeline([\n",
        "    ('features', combined_features),\n",
        "    ('clf', BernoulliNB())\n",
        "    ])\n",
        "\n",
        "parameters = {'clf__alpha': (0.5, 0.5, 1),\n",
        "              'clf__fit_prior': (True, False)}\n",
        "\n",
        "clf = GridSearchCV(clf, parameters, cv=3)\n",
        "\n",
        "clf = clf.fit(combined_train, train_labels)\n",
        "y_pred = clf.predict(combined_test)\n",
        "test_model(clf, y_pred, test_labels)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Precision: 0.6987\n",
            "Test Recall: 0.7105\n",
            "Test F-Score: : 0.7020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gB9GzDRkJM6C"
      },
      "source": [
        "**LogisticRegressionCV (n=10)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3NHRISh0IojU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "05fb4a65-c985-49c7-8b81-e3ca4f287e66"
      },
      "source": [
        "clf = Pipeline([\n",
        "    ('features', combined_features),\n",
        "    ('clf', LogisticRegressionCV(cv=3, solver='liblinear'))\n",
        "])\n",
        "\n",
        "clf = clf.fit(combined_train, train_labels)\n",
        "y_pred = clf.predict(combined_test)\n",
        "test_model(clf, y_pred, test_labels)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Precision: 0.7222\n",
            "Test Recall: 0.7328\n",
            "Test F-Score: : 0.7243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "X64LZab5JSE7"
      },
      "source": [
        "**MLPClassifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0dtt7eGKGA6K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a4176b89-e516-4ab1-8b3b-a2204b42a12f"
      },
      "source": [
        "clf = Pipeline([\n",
        "    ('features', combined_features),\n",
        "    ('clf', MLPClassifier(hidden_layer_sizes=(100, 150, 2), max_iter=400, \n",
        "                          activation='relu', random_state=42, \n",
        "                          validation_fraction=0.3, early_stopping=True, \n",
        "                          warm_start=True, solver='adam'))\n",
        "])\n",
        "\n",
        "clf = clf.fit(combined_train, train_labels)\n",
        "y_pred = clf.predict(combined_test)\n",
        "test_model(clf, y_pred, test_labels)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Precision: 0.6991\n",
            "Test Recall: 0.7153\n",
            "Test F-Score: : 0.6755\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}